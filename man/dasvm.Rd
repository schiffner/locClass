% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dasvm.R
\name{dasvm}
\alias{dasvm}
\alias{dasvm.default}
\alias{dasvm.formula}
\title{Discriminant Adaptive Support Vector Machine}
\usage{
dasvm(x, ...)

\method{dasvm}{formula}(formula, data = NULL, case.weights = rep(1,
  nrow(data)), ..., subset, na.action = na.omit, scale = TRUE)

\method{dasvm}{default}(x, y = NULL, wf = c("biweight", "cauchy", "cosine",
  "epanechnikov", "exponential", "gaussian", "optcosine", "rectangular",
  "triangular"), bw, k, nn.only, itr = 3, method = c("prob", "decision"),
  scale = TRUE, type = NULL, case.weights = rep(1, nrow(x)), ...,
  subset = NULL, na.action = na.omit)
}
\arguments{
\item{x}{(Required if no \code{formula} is given as principal argument.) A data matrix, a 
vector, or a sparse matrix (object of class \code{\link[Matrix]{Matrix}} provided by the 
\pkg{Matrix} package, or of class \code{\link[SparseM]{matrix.csr}} provided by the \pkg{SparseM} 
package, or of class \code{\link[slam]{simple_triplet_matrix}} provided by the \pkg{slam} package).}

\item{formula}{A symbolic description of the model to be fit.}

\item{data}{An optional data frame containing the variables in the model. By default 
the variables are taken from the environment which \code{dasvm} is called from.}

\item{case.weights}{Initial observation weights (defaults to a vector of 1s).}

\item{subset}{An index vector specifying the cases to be used in the training sample. 
(NOTE: If given, this argument must be named.)}

\item{na.action}{A function to specify the action to be taken if \code{NA}s are found. The default action is 
\code{na.omit}, which leads to rejection of cases with missing values on any required variable. An alternative 
is \code{na.fail}, which causes an error if \code{NA} cases are found. (NOTE: If given, this argument must be named.)}

\item{scale}{A logical vector indicating the variables to be scaled. If \code{scale} is of length 1, the 
value is recycled as many times as needed. Per default, data are scaled internally (both \code{x} and \code{y} 
variables) to zero mean and unit variance. The center and scale values are returned and used for later 
predictions.}

\item{y}{(Only if no \code{formula} is given as principal argument.) A response vector with 
one label for each row/component of x. Should be a factor, otherwise it is coerced to a factor
with a warning.}

\item{wf}{A window function which is used to calculate weights that are introduced into 
the fitting process. Either a character string or a function, e.g. \code{wf = function(x) exp(-x)}.
For details see the documentation for \code{\link[=biweight]{wfs}}.}

\item{bw}{(Required only if \code{wf} is a string.) The bandwidth parameter of the window function. 
(See \code{\link[=biweight]{wfs}}.)}

\item{k}{(Required only if \code{wf} is a string.) The number of nearest neighbors of the decision 
boundary to be used in the fitting process. 
(See \code{\link[=biweight]{wfs}}.)}

\item{nn.only}{(Required only if \code{wf} is a string indicating a window function with infinite 
support and if \code{k} is specified.) Should
only the \code{k} nearest neighbors or all observations receive positive weights? 
(See \code{\link[=biweight]{wfs}}.)}

\item{itr}{Number of iterations for model fitting, defaults to 3. See also the Details section.}

\item{method}{The method for adaptation to the decision boundary, either \code{"prob"} or \code{"decision"}. 
Defaults to "prob".}

\item{type}{\code{dasvm} can be used only as a classification machine, hence valid options are:
\itemize{
\item \code{C-classification}
\item \code{nu-classification}
}
\code{C-classification} is default.}

\item{\dots}{Further parameters that are passed to \code{wsvm.default}, e.g. \code{kernel}, \code{degree}, 
\code{gamma}, \code{coef0}, \code{cost}, \code{nu}, \code{class.weights}, \code{case.weights}, \code{cachesize}, 
\code{tolerance}, \code{shrinking}, \code{cross}, \code{probability}, \code{fitted}, and 
\code{seed}. Note that \code{epsilon} is a parameter that is only needed in the regression case and thus will
have no effect if specified.}
}
\value{
An object of class \code{"dasvm.formula"} or \code{"dasvm"} inheriting from \code{"wsvm.formula"} or 
\code{"wsvm"} and \code{"svm"}, a \code{list} containing the following components:
 \item{case.weights}{A list of length \code{itr + 1}. The initial observation weights (a vector of 1s if none were given) 
   and the observation weights calculated in the individual iterations.}
 \item{itr}{The number of iterations used.}
 \item{wf}{The window function used. Always a function, even if the input was a string.}
 \item{bw}{(Only if \code{wf} is a string or was generated by means of one of the functions documented in \code{\link[=biweight]{wfs}}.) 
  The bandwidth used, \code{NULL} if \code{bw} was not specified.}
\item{k}{(Only if \code{wf} is a string or was generated by means of one of the functions documented in \code{\link[=biweight]{wfs}}.) 
  The number of nearest neighbors used, \code{NULL} if \code{k} was not specified.}
 \item{nn.only}{(Logical. Only if \code{wf} is a string or was generated by means of one of the functions documented 
in \code{\link[=biweight]{wfs}} and if \code{k} was
 specified.) \code{TRUE} if only the \code{k} nearest neighbors recieve a positive weight, \code{FALSE} otherwise.}
 \item{adaptive}{(Logical.) \code{TRUE} if the bandwidth of \code{wf} is adaptive to the local density of data points, 
\code{FALSE} if the bandwidth is fixed.}
 \item{call}{The (matched) function call.}
}
\description{
A local version of Support Vector Machines for classification that puts increased emphasis on a good model 
fit near the decision boundary.
}
\details{
The idea of Hand and Vinciotti (2003) to put increased weight on observations near 
the decision boundary is generalized to the multiclass case and applied to 
Support Vector Machines (SVM).

Two different methods are implemented to achieve this.
The first one is based on the decision values. 
In order to deal with multiclass problems with k classes, \eqn{k>2}, \sQuote{libsvm} uses the
\sQuote{one-against-one}-approach, in which \eqn{k(k-1)/2} binary classifiers are
trained; the appropriate class is found by a voting scheme.
Hence, there are decision values for every binary classification problem. The absolute decision 
values are proportional to the distance between the training observations and the decision boundary.
A window function is applied to these distances in order to get observation weights.

The second method is based on posterior probabilities. 
The probability model for classification fits a logistic distribution
using maximum likelihood to the decision values of all binary
classifiers, and computes the a-posteriori class probabilities for the
multi-class problem using quadratic optimization. The probabilistic
regression model assumes (zero-mean) laplace-distributed errors for the
predictions, and estimates the scale parameter using maximum likelihood.
Observation weights are calculated based on the differences between the two largest estimated 
posterior probabilities.

Since the decision boundary is not known in advance an iterative procedure is required.
First, an unweighted SVM is fitted to the data. 
Then either based on the estimated decision values or the estimated posterior probabilities 
observation weights are calculated.
Then a weighted SVM (see \code{\link{wsvm}}) is fitted using these weights. 
Calculation of weights and model fitting is done several times in turn. 
The number of iterations is determined by the \code{itr}-argument that defaults to 3.

In order to calculate the weights a window function is applied to the decision values or 
posterior probabilities.
The name of the window function (\code{wf}) can be specified as a character string.
In this case the window function is generated internally in \code{dasvm}. Currently
supported are \code{"biweight"}, \code{"cauchy"}, \code{"cosine"}, \code{"epanechnikov"}, 
\code{"exponential"}, \code{"gaussian"}, \code{"optcosine"}, \code{"rectangular"} and 
\code{"triangular"}.

Moreover, it is possible to generate the window functions mentioned above in advance 
(see \code{\link[=biweight]{wfs}}) and pass them to \code{dasvm}.

Any other function implementing a window function can also be used as \code{wf} argument.
This allows the user to try own window functions.
See help on \code{\link[=biweight]{wfs}} for details.

\code{dasvm} calls \code{\link{wsvm}} internally which is a version of Support Vector Machines that
can deal with case weights and which is a modified version of the \code{\link[e1071]{svm}} 
function in package \pkg{e1071} written by David Meyer 
(based on C/C++-code by Chih-Chung Chang and Chih-Jen Lin).
An extension of LIBSVM that can deal with case weights written by
Ming-Wei Chang, Hsuan-Tien Lin, Ming-Hen Tsai, Chia-Hua Ho and Hsiang-Fu Yu
is used. It is available at
\url{http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances}.

\code{libsvm} internally uses a sparse data representation, which is 
 also high-level supported by the package \pkg{SparseM}.
 
 If the predictor variables include factors, the formula interface must be used to get a
 correct model matrix.

Data are scaled internally, usually yielding better results. 
Parameters of SVM-models usually \emph{must} be tuned to yield sensible results!
}
\examples{
fit <- dasvm(Species ~ ., data = iris, wf = "gaussian", bw = 0.5)
pred <- predict(fit)
mean(pred != iris$Species)

}
\references{
Hand, D. J., Vinciotti, V. (2003), Local versus global models for classification problems: 
Fitting models where it matters, \emph{The American Statistician}, \bold{57(2)} 124--130.
}
\seealso{
\code{\link{predict.dasvm}}, \code{\link{wsvm}} for a weighted version of Support Vector Machines.
}
\keyword{classif}

